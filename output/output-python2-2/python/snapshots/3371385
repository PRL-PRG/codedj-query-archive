#!/usr/bin/python
#  file     : $URL$
#  revision : $LastChangedRevision$  $LastChangedBy$
#  date     : $LastChangedDate$


# This script is a simple, generic model generator. A number of different
# models are created with varying number of clusters, depth of the supply path
# and number of demands per cluster. By evaluating the runtime of these models
# we can evaluate different aspects of Frepple's scalability.
#
# This test script is meant more as a sample for your own tests on evaluating
# scalability.
#
# The autogenerated supply network looks schematically as follows:
#   [ Operation -> buffer ] ...   [ -> Operation -> buffer ]  [ Delivery ]
#   [ Operation -> buffer ] ...   [ -> Operation -> buffer ]  [ Delivery ]
#   [ Operation -> buffer ] ...   [ -> Operation -> buffer ]  [ Delivery ]
#   [ Operation -> buffer ] ...   [ -> Operation -> buffer ]  [ Delivery ]
#   [ Operation -> buffer ] ...   [ -> Operation -> buffer ]  [ Delivery ]
#       ...                                  ...
# Each row represents a cluster.
# The operation+buffer are repeated as many times as the depth of the supply
# path parameter.
# In each cluster a single item is defined, and a parametrizable number of
# demands is placed on the cluster.

import os, os.path, sys, random


# This function generates a random date
def getDate():
  month = "%02d" % (int(random.uniform(0,12))+1)
  day = "%02d" % (int(random.uniform(0,28))+1)
  return "2007-%s-%sT00:00:00" % (month,day)


# This routine creates the model data file.
# The return value is an indication of the size of the model.
def create (cluster, demand, level):
  # Initialize
  size = 0
  out = open("input.xml","wt")
  print >>out, "<PLAN xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">"

  # Items
  print >>out, "<ITEMS>"
  for i in range(cluster):
    ++size
    print >>out, ("<ITEM NAME=\"Item C%d\">" +
      "<OPERATION NAME=\"Del C%d\"> <FLOWS>" +
        "<FLOW xsi:type=\"FLOW_START\" QUANTITY=\"-1\">" +
        "<BUFFER NAME=\"Buffer C%dL1\"/></FLOW>" +
      "</FLOWS></OPERATION></ITEM>") % (i,i,i)
  print >>out, "</ITEMS>"

  # Demands
  print >>out, "<DEMANDS>"
  for i in range(cluster):
    for j in range(demand):
      size += 2 # since a demand will result in multiple operationplans
      print >>out, ("<DEMAND NAME=\"Demand C%dD%d\" " +
        "QUANTITY=\"1\" DUE=\"%s\">" +
        "<ITEM NAME=\"Item C%d\"/></DEMAND>") % (i,j,getDate(),i)
  print >>out, "</DEMANDS>"

  # Operations
  print >>out, "<OPERATIONS>"
  for i in range(cluster):
    for j in range(level):
      size += 2
      print >>out, ("<OPERATION NAME=\"Oper C%dO%d\" " +
        "xsi:type=\"OPERATION_FIXED_TIME\" " +
        "DURATION=\"%d:00:00\"> <FLOWS>" +
        "<FLOW xsi:type=\"FLOW_END\" QUANTITY=\"1\">" +
        "<BUFFER NAME=\"Buffer C%dL%d\">" +
        "<PRODUCING NAME=\"Oper C%dO%d\"/></BUFFER></FLOW>" +
        "<FLOW xsi:type=\"FLOW_START\" QUANTITY=\"-1\">" +
        "<BUFFER NAME=\"Buffer C%dL%d\"/></FLOW>" +
        "</FLOWS></OPERATION>") % (i, j, 24*int(random.uniform(0,10)+1), i, j, i, j, i, j+1)

  # Create material supply
  for i in range(cluster):
    print >>out, ("<OPERATION NAME=\"Supply C%d\"> " +
        "<FLOWS><FLOW xsi:type=\"FLOW_END\" QUANTITY=\"1\">" +
        "<BUFFER NAME=\"Buffer C%dL%d\"/>" +
        "</FLOW></FLOWS></OPERATION>") % (i, i, level+1)
  print >>out, "</OPERATIONS>\n<OPERATION_PLANS>"
  for i in range(cluster):
    print >>out, ("<OPERATION_PLAN ID=\"%d\" OPERATION=\"Supply C%d\" " +
        "START=\"2007-05-01T00:00:00\" QUANTITY=\"%d\" " +
        "LOCKED=\"true\" />") % (i+1, i, demand)
  print >>out, "</OPERATION_PLANS>"

  # Tail of the output file
  print >>out, "</PLAN>"
  out.close()

  # Return size indication
  return size


# Initialize random number generator in a reproducible way
random.seed(100)

# Loop over all cluster values
runtimes = {}
print "Clusters\tDemands\tLevels\tRuntime"
for cluster in [100,200,300]:

  # Loop over all demand values
  for demand in [10,20,30]:

    # Loop over all level values
    for level in [1,5,9]:

      # Creating model data file
      size = create(cluster, demand, level)

      # Run the model
      starttime = os.times()
      out = os.popen(os.environ['EXECUTABLE'] + "  ./commands.xml")
      while True:
        i = out.readline()
        if not i: break
        print i.strip()
      if out.close() != None:
        print "Planner exited abnormally"
        sys.exit(1)

      # Measure the time
      endtime = os.times()
      runtimes[size] = endtime[4]-starttime[4]
      print "%d\t%d\t%d\t%.3f" % (cluster,demand,level,runtimes[size])

      # Clean up the files
      os.remove("input.xml")
      os.remove("output.xml")
      #if os.path.isfile("input_%d_%d_%d.xml" % (cluster,demand,level)):
      #  os.remove("input_%d_%d_%d.xml" % (cluster,demand,level))
      #if os.path.isfile("output_%d_%d_%d.xml" % (cluster,demand,level)):
      #  os.remove("output_%d_%d_%d.xml" % (cluster,demand,level))
      #os.rename("input.xml", "input_%d_%d_%d.xml" % (cluster,demand,level))
      #os.rename("output.xml", "output_%d_%d_%d.xml" % (cluster,demand,level))

# A pass criterium could be defined here.
# Right now the test pass when all cases finish successfully, and the timing
# isn't considered to evaluate pass or fail.
# Since the data import and bottleneck are the most timeconsuming operations
# a timing that scales close to linear with the model size is expected.

print "\nTest passed"
