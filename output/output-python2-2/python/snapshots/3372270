#!/usr/bin/python
#  file     : $URL$
#  revision : $LastChangedRevision$  $LastChangedBy$
#  date     : $LastChangedDate$
#  email    : jdetaeye@users.sourceforge.net

# This script is a simple, generic model generator. A number of different
# models are created with varying number of clusters, depth of the supply path
# and number of demands per cluster. By evaluating the runtime of these models
# we can evaluate different aspects of Frepple's scalability.
#
# This test script is meant more as a sample for your own tests on evaluating
# scalability.
#
# The autogenerated supply network looks schematically as follows:
#   [ Operation -> buffer ] ...   [ -> Operation -> buffer ]  [ Delivery ]
#   [ Operation -> buffer ] ...   [ -> Operation -> buffer ]  [ Delivery ]
#   [ Operation -> buffer ] ...   [ -> Operation -> buffer ]  [ Delivery ]
#   [ Operation -> buffer ] ...   [ -> Operation -> buffer ]  [ Delivery ]
#   [ Operation -> buffer ] ...   [ -> Operation -> buffer ]  [ Delivery ]
#       ...                                  ...
# Each row represents a cluster.
# The operation+buffer are repeated as many times as the depth of the supply
# path parameter.
# In each cluster a single item is defined, and a parametrizable number of
# demands is placed on the cluster.


import os, os.path, sys, random
from datetime import timedelta, datetime, date

from django.conf import settings
from django.db import connection, transaction, backend
from django.core.management.color import no_style

from freppledb.input.models import *

startdate = datetime(2007,1,1)


@transaction.commit_manually
def erase_model():
  '''
  This routine erase all model data from the database.
  All exceptions are propagated to a higher level.
  '''
  cursor = connection.cursor()
  # SQLite specials
  if settings.DATABASE_ENGINE == 'sqlite3':
    cursor.execute('PRAGMA synchronous = OFF')  # Performance improvement
  # Delete all records from the tables
  sql_list = backend.get_sql_flush(no_style(), [
    'out_problem','out_flowplan','out_loadplan','out_demandpegging',
    'out_operationplan','dates','demand','forecastdemand','forecast','flow',
    'resourceload','buffer','resource','operationplan','item','suboperation',
    'operation','location','bucket','calendar','customer'
    ], [] )
  try:
    for sql in sql_list: cursor.execute(sql)
  finally:
    transaction.commit()
  # SQLite specials
  if settings.DATABASE_ENGINE == 'sqlite3':
    cursor.execute('vacuum')   # Shrink the database file


@transaction.commit_manually
def createDates():
  '''
  Populate the bucketization table 'dates' and a calendar that marks the
  working days monday through friday.
  '''
  global startdate

  # Performance improvement for sqlite during the bulky creation transactions
  if settings.DATABASE_ENGINE == 'sqlite3':
    connection.cursor().execute('PRAGMA synchronous=OFF')
  try:
    cal = Calendar(name="working days")
    cal.save()
    for i in range(365):
      # Loop through 1 year of daily buckets
      curdate = startdate + timedelta(i)
      month = int(curdate.strftime("%m"))  # an integer in the range 1 - 12
      quarter = (month-1) / 3 + 1          # an integer in the range 1 - 4
      year = int(curdate.strftime("%Y"))
      dayofweek = int(curdate.strftime("%w")) # day of the week, 0 = sunday, 1 = monday, ...

      # Main entry
      Dates(
        day = curdate,
        day_start = curdate,
        day_end = curdate + timedelta(1),
        dayofweek = dayofweek,
        week = curdate.strftime("%y W%W"),     # Weeks are starting on monday
        week_start = curdate - timedelta((dayofweek+6)%7),
        week_end = curdate - timedelta((dayofweek+6)%7-7),
        month =  curdate.strftime("%b %y"),
        month_start = date(year, month, 1),
        month_end = date(year+month/12, month+1-12*(month/12), 1),
        quarter = "%02d Q%s" % (year-2000,quarter),
        quarter_start = date(year, quarter*3-2, 1),
        quarter_end = date(year+quarter/4, quarter*3+1-12*(quarter/4), 1),
        year = curdate.strftime("%Y"),
        year_start = date(year,1,1),
        year_end = date(year+1,1,1),
        ).save()

      # Create a calendar bucket
      if dayofweek == 1:
        # A bucket for the working week: monday through friday
        Bucket(startdate = curdate, value=1, calendar=cal).save()
      elif dayofweek == 6:
        # A bucket for the weekend
        Bucket(startdate = curdate, value=0, calendar=cal).save()
  finally:
    transaction.commit()


@transaction.commit_manually
def updateTelescope(min_day_horizon, min_week_horizon):
  '''
  Update for the telescopic horizon.
  The first argument specifies the minimum number of daily buckets. Additional
  daily buckets will be appended till we come to a monday. At that date weekly
  buckets are starting.
  The second argument specifies the minimum horizon with weeks before the
  monthly buckets. The last weekly bucket can be a partial one: starting on
  monday and ending on the first day of the next calendar month.
  '''
  # Performance improvement for sqlite during the bulky creation transactions
  if settings.DATABASE_ENGINE == 'sqlite3':
    connection.cursor().execute('PRAGMA synchronous=OFF')
  mode = 'day'
  limit = (Plan.objects.all()[0].currentdate + timedelta(min_day_horizon)).date()
  try:
    for i in Dates.objects.all():
      if mode == 'day':
        i.default = str(i.day)[2:]  # Leave away the leading century, ie "20"
        i.default_start = i.day_start
        i.default_end = i.day_end
        if i.day >= limit and i.dayofweek == 0:
          mode = 'week'
          limit = (Plan.objects.all()[0].currentdate + timedelta(min_week_horizon)).date()
          limit =  date(limit.year+limit.month/12, limit.month+1-12*(limit.month/12), 1)
      elif i.day < limit:
        i.default = i.week
        i.default_start = i.week_start
        i.default_end = (i.week_end > limit and limit) or i.week_end
      else:
        i.default = i.month
        i.default_start = i.month_start
        i.default_end = i.month_end
      i.save()
  finally:
    transaction.commit()


@transaction.commit_manually
def create_model (cluster, demand, forecast_per_item, level, resource, resource_size):
  '''
  This routine populates the database with a sample dataset.
  '''
  # Initialization
  global startdate
  random.seed(100) # Initialize random seed to get reproducible results
  cnt = 100000     # a counter for operationplan identifiers

  # Performance improvement for sqlite during the bulky creation transactions
  if settings.DATABASE_ENGINE == 'sqlite3':
    connection.cursor().execute('PRAGMA synchronous=OFF')

  try:
    # Dates
    print "Creating dates..."
    createDates()
    updateTelescope(10, 40)

    # Plan start date
    print "Creating plan..."
    try:
      p = Plan.objects.all()[0]
      p.currentdate = startdate
      p.save()
    except:
      # No plan exists yet
      p = Plan(name="frepple", current=startdate)
      p.save()

    # Create a random list of categories to choose from
    categories = [ 'cat A','cat B','cat C','cat D','cat E','cat F','cat G' ]

    # Create customers
    print "Creating customers..."
    cust = []
    for i in range(100):
      c = Customer(name = 'Cust %03d' % i)
      cust.append(c)
      c.save()
    transaction.commit()

    # Create resources and their calendars
    print "Creating resources and calendars..."
    res = []
    for i in range(resource):
      loc = Location(name='Loc %05d' % int(random.uniform(1,cluster)))
      loc.save()
      cal = Calendar(name='capacity for res %03d' %i, category='capacity')
      bkt = Bucket(startdate=startdate, value=resource_size, calendar=cal)
      cal.save()
      bkt.save()
      r = Resource(name = 'Res %03d' % i, maximum=cal, location=loc)
      res.append(r)
      r.save()
    transaction.commit()

    # Loop over all clusters
    durations = [ 86400, 86400*2, 86400*3, 86400*5, 86400*6 ]
    workingdays = Calendar.objects.get(name="working days")
    for i in range(cluster):
      print "Creating cluster %d..." % i

      # location
      loc = Location(name='Loc %05d' % i)
      loc.save()

      # Item and delivery operation
      oper = Operation(name='Del %05d' % i, sizemultiple=1)
      oper.save()
      it = Item(name='Itm %05d' % i, operation=oper, category=random.choice(categories))
      it.save()

      # Forecast
      fcst = Forecast( \
        name='Forecast item %05d' % i,
        calendar=workingdays,
        item=it,
        priority=3, # Low priority: prefer planning orders over forecast
        )
      fcst.save()
      # This method will take care of distributing a forecast quantity over the entire
      # horizon, respecting the bucket weights.
      fcst.setTotal(startdate, startdate + timedelta(365), forecast_per_item)

      # Level 0 buffer
      buf = Buffer(name='Buf %05d L00' % i,
        item=it,
        location=loc,
        category='00'
        )
      fl = Flow(operation=oper, thebuffer=buf, quantity=-1)
      fl.save()

      # Demand
      for j in range(demand):
        dm = Demand(name='Dmd %05d %05d' % (i,j),
          item=it,
          quantity=int(random.uniform(1,6)),
          # Exponential distribution of due dates, with an average of 30 days.
          due= startdate + timedelta(random.expovariate(float(1)/30)),
          # Orders have higher priority than forecast
          priority=random.choice([1,2]),
          customer=random.choice(cust),
          category=random.choice(categories)
          )
        dm.save()

      # Upstream operations and buffers
      for k in range(level):
        if k == 1 and res:
          # Create a resource load for operations on level 1
          oper = Operation(name='Oper %05d L%02d' % (i,k),
            type='OPERATION_TIME_PER',
            duration_per=86400,
            sizemultiple=1,
            )
          oper.save()
          Load(resource=random.choice(res), operation=oper).save()
        else:
          oper = Operation(name='Oper %05d L%02d' % (i,k),
            duration=random.choice(durations),
            sizemultiple=1,
            )
          oper.save()
        buf.producing = oper
        buf.save()
        Flow(operation=oper, thebuffer=buf, quantity=1, type="FLOW_END").save()
        buf = Buffer(name='Buf %05d L%02d' % (i,k+1),
          item=it,
          location=loc,
          category='%02d' % (k+1)
          )
        # Some inventory in random buffers
        if random.uniform(0,1) > 0.8: buf.onhand=int(random.uniform(5,20))
        buf.save()
        Flow(operation=oper, thebuffer=buf, quantity=-1).save()

      # Create supply operation
      oper = Operation(name='Sup %05d' % i, sizemultiple=1)
      oper.save()
      Flow(operation=oper, thebuffer=buf, quantity=1).save()

      # Create actual supply
      total_supply = forecast_per_item * 12
      while total_supply > 0:
          cnt += 1
          arrivaldate = startdate + timedelta(int(random.uniform(0,365)*12)/12)
          opplan = OperationPlan(identifier=cnt,
            operation=oper,
            quantity=int(random.uniform(10,20)),
            startdate=arrivaldate,
            enddate=arrivaldate,
            )
          total_supply -= opplan.quantity
          opplan.save()

      # Commit the current cluster
      transaction.commit()

  finally:
    # Commit it all, even in case of exceptions
    transaction.commit()
